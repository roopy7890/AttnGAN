{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Hello, Colaboratory",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/roopy7890/AttnGAN/blob/master/code/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "K4vFD-hOxftV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 387
        },
        "outputId": "1137ac58-edf8-4380-de2b-346e3876e78f"
      },
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "from miscc.config import cfg, cfg_from_file\n",
        "from datasets import TextDataset\n",
        "from trainer import condGANTrainer as trainer\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "import random\n",
        "import pprint\n",
        "import datetime\n",
        "import dateutil.tz\n",
        "import argparse\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "dir_path = (os.path.abspath(os.path.join(os.path.realpath(__file__), './.')))\n",
        "sys.path.append(dir_path)\n",
        "\n",
        "\n",
        "def parse_args():\n",
        "    parser = argparse.ArgumentParser(description='Train a AttnGAN network')\n",
        "    parser.add_argument('--cfg', dest='cfg_file',\n",
        "                        help='optional config file',\n",
        "                        default='cfg/bird_attn2.yml', type=str)\n",
        "    parser.add_argument('--gpu', dest='gpu_id', type=int, default=-1)\n",
        "    parser.add_argument('--data_dir', dest='data_dir', type=str, default='')\n",
        "    parser.add_argument('--manualSeed', type=int, help='manual seed')\n",
        "    args = parser.parse_args()\n",
        "    return args\n",
        "\n",
        "\n",
        "def gen_example(wordtoix, algo):\n",
        "    '''generate images from example sentences'''\n",
        "    from nltk.tokenize import RegexpTokenizer\n",
        "    filepath = '%s/example_filenames.txt' % (cfg.DATA_DIR)\n",
        "    data_dic = {}\n",
        "    with open(filepath, \"r\") as f:\n",
        "        filenames = f.read().decode('utf8').split('\\n')\n",
        "        for name in filenames:\n",
        "            if len(name) == 0:\n",
        "                continue\n",
        "            filepath = '%s/%s.txt' % (cfg.DATA_DIR, name)\n",
        "            with open(filepath, \"r\") as f:\n",
        "                print('Load from:', name)\n",
        "                sentences = f.read().decode('utf8').split('\\n')\n",
        "                # a list of indices for a sentence\n",
        "                captions = []\n",
        "                cap_lens = []\n",
        "                for sent in sentences:\n",
        "                    if len(sent) == 0:\n",
        "                        continue\n",
        "                    sent = sent.replace(\"\\ufffd\\ufffd\", \" \")\n",
        "                    tokenizer = RegexpTokenizer(r'\\w+')\n",
        "                    tokens = tokenizer.tokenize(sent.lower())\n",
        "                    if len(tokens) == 0:\n",
        "                        print('sent', sent)\n",
        "                        continue\n",
        "\n",
        "                    rev = []\n",
        "                    for t in tokens:\n",
        "                        t = t.encode('ascii', 'ignore').decode('ascii')\n",
        "                        if len(t) > 0 and t in wordtoix:\n",
        "                            rev.append(wordtoix[t])\n",
        "                    captions.append(rev)\n",
        "                    cap_lens.append(len(rev))\n",
        "            max_len = np.max(cap_lens)\n",
        "\n",
        "            sorted_indices = np.argsort(cap_lens)[::-1]\n",
        "            cap_lens = np.asarray(cap_lens)\n",
        "            cap_lens = cap_lens[sorted_indices]\n",
        "            cap_array = np.zeros((len(captions), max_len), dtype='int64')\n",
        "            for i in range(len(captions)):\n",
        "                idx = sorted_indices[i]\n",
        "                cap = captions[idx]\n",
        "                c_len = len(cap)\n",
        "                cap_array[i, :c_len] = cap\n",
        "            key = name[(name.rfind('/') + 1):]\n",
        "            data_dic[key] = [cap_array, cap_lens, sorted_indices]\n",
        "    algo.gen_example(data_dic)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    args = parse_args()\n",
        "    if args.cfg_file is not None:\n",
        "        cfg_from_file(args.cfg_file)\n",
        "\n",
        "    if args.gpu_id != -1:\n",
        "        cfg.GPU_ID = args.gpu_id\n",
        "    else:\n",
        "        cfg.CUDA = False\n",
        "\n",
        "    if args.data_dir != '':\n",
        "        cfg.DATA_DIR = args.data_dir\n",
        "    print('Using config:')\n",
        "    pprint.pprint(cfg)\n",
        "\n",
        "    if not cfg.TRAIN.FLAG:\n",
        "        args.manualSeed = 100\n",
        "    elif args.manualSeed is None:\n",
        "        args.manualSeed = random.randint(1, 10000)\n",
        "    random.seed(args.manualSeed)\n",
        "    np.random.seed(args.manualSeed)\n",
        "    torch.manual_seed(args.manualSeed)\n",
        "    if cfg.CUDA:\n",
        "        torch.cuda.manual_seed_all(args.manualSeed)\n",
        "\n",
        "    now = datetime.datetime.now(dateutil.tz.tzlocal())\n",
        "    timestamp = now.strftime('%Y_%m_%d_%H_%M_%S')\n",
        "    output_dir = '../output/%s_%s_%s' % \\\n",
        "        (cfg.DATASET_NAME, cfg.CONFIG_NAME, timestamp)\n",
        "\n",
        "    split_dir, bshuffle = 'train', True\n",
        "    if not cfg.TRAIN.FLAG:\n",
        "        # bshuffle = False\n",
        "        split_dir = 'test'\n",
        "\n",
        "    # Get data loader\n",
        "    imsize = cfg.TREE.BASE_SIZE * (2 ** (cfg.TREE.BRANCH_NUM - 1))\n",
        "    image_transform = transforms.Compose([\n",
        "        transforms.Scale(int(imsize * 76 / 64)),\n",
        "        transforms.RandomCrop(imsize),\n",
        "        transforms.RandomHorizontalFlip()])\n",
        "    dataset = TextDataset(cfg.DATA_DIR, split_dir,\n",
        "                          base_size=cfg.TREE.BASE_SIZE,\n",
        "                          transform=image_transform)\n",
        "    assert dataset\n",
        "    dataloader = torch.utils.data.DataLoader(\n",
        "        dataset, batch_size=cfg.TRAIN.BATCH_SIZE,\n",
        "        drop_last=True, shuffle=bshuffle, num_workers=int(cfg.WORKERS))\n",
        "\n",
        "    # Define models and go to train/evaluate\n",
        "    algo = trainer(output_dir, dataloader, dataset.n_words, dataset.ixtoword)\n",
        "\n",
        "    start_t = time.time()\n",
        "    if cfg.TRAIN.FLAG:\n",
        "        algo.train()\n",
        "    else:\n",
        "        '''generate images from pre-extracted embeddings'''\n",
        "        if cfg.B_VALIDATION:\n",
        "            algo.sampling(split_dir)  # generate images for the whole valid dataset\n",
        "        else:\n",
        "            gen_example(dataset.wordtoix, algo)  # generate images for customized captions\n",
        "    end_t = time.time()\n",
        "    print('Total time for training:', end_t - start_t)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-b9e9c364515d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprint_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmiscc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfg_from_file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTextDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtrainer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcondGANTrainer\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'miscc'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    }
  ]
}